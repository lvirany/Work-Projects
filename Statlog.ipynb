{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOPwX2mC7AWA/ZInOv75TgO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lvirany/Work-Projects/blob/main/Statlog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install cirq\n",
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "id": "ppQbWjk9Aa_n"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5hmtNcCAEEj",
        "outputId": "1bdbcaf1-a6eb-4302-a474-65c1d9c8ecb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           name     role         type     demographic  \\\n",
            "0    Attribute1  Feature  Categorical            None   \n",
            "1    Attribute2  Feature      Integer            None   \n",
            "2    Attribute3  Feature  Categorical            None   \n",
            "3    Attribute4  Feature  Categorical            None   \n",
            "4    Attribute5  Feature      Integer            None   \n",
            "5    Attribute6  Feature  Categorical            None   \n",
            "6    Attribute7  Feature  Categorical           Other   \n",
            "7    Attribute8  Feature      Integer            None   \n",
            "8    Attribute9  Feature  Categorical  Marital Status   \n",
            "9   Attribute10  Feature  Categorical            None   \n",
            "10  Attribute11  Feature      Integer            None   \n",
            "11  Attribute12  Feature  Categorical            None   \n",
            "12  Attribute13  Feature      Integer             Age   \n",
            "13  Attribute14  Feature  Categorical            None   \n",
            "14  Attribute15  Feature  Categorical           Other   \n",
            "15  Attribute16  Feature      Integer            None   \n",
            "16  Attribute17  Feature  Categorical      Occupation   \n",
            "17  Attribute18  Feature      Integer            None   \n",
            "18  Attribute19  Feature       Binary            None   \n",
            "19  Attribute20  Feature       Binary           Other   \n",
            "20        class   Target       Binary            None   \n",
            "\n",
            "                                          description   units missing_values  \n",
            "0                 Status of existing checking account    None             no  \n",
            "1                                            Duration  months             no  \n",
            "2                                      Credit history    None             no  \n",
            "3                                             Purpose    None             no  \n",
            "4                                       Credit amount    None             no  \n",
            "5                               Savings account/bonds    None             no  \n",
            "6                            Present employment since    None             no  \n",
            "7   Installment rate in percentage of disposable i...    None             no  \n",
            "8                             Personal status and sex    None             no  \n",
            "9                          Other debtors / guarantors    None             no  \n",
            "10                            Present residence since    None             no  \n",
            "11                                           Property    None             no  \n",
            "12                                                Age   years             no  \n",
            "13                            Other installment plans    None             no  \n",
            "14                                            Housing    None             no  \n",
            "15            Number of existing credits at this bank    None             no  \n",
            "16                                                Job    None             no  \n",
            "17  Number of people being liable to provide maint...    None             no  \n",
            "18                                          Telephone    None             no  \n",
            "19                                     foreign worker    None             no  \n",
            "20                                  1 = Good, 2 = Bad    None             no  \n",
            "Best Parameters: {'alpha': 0.01, 'class_weight': {1: 1.0, 2: 2.0}}\n",
            "Cross-Validation Accuracy Scores: [0.70625 0.5875  0.63125 0.75    0.73125]\n",
            "Mean Cross-Validation Accuracy: 68.12%\n",
            "Train Accuracy: 54.00%\n",
            "Test Accuracy: 70.50%\n",
            "Predicted Defaults (Test): [1 1 1 1 1 1 1 1 1 1]\n",
            "Actual Defaults (Test): [2 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cirq\n",
        "import gc # Import the gc module\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV # 12/16\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import pickle\n",
        "\n",
        "# Fetch the dataset\n",
        "statlog_german_credit_data = fetch_ucirepo(id=144)\n",
        "\n",
        "# Load dataset features and targets\n",
        "X = statlog_german_credit_data.data.features  # Features as DataFrame\n",
        "y = statlog_german_credit_data.data.targets   # Targets as Series\n",
        "\n",
        "# Inspect dataset metadata\n",
        "#print(statlog_german_credit_data.metadata)\n",
        "print(statlog_german_credit_data.variables)\n",
        "\n",
        "# Preprocess the data\n",
        "# Normalize the features to [0, 1]\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "# Encode categorical features\n",
        "categorical_columns = ['Attribute1', 'Attribute3', 'Attribute4', 'Attribute6', 'Attribute7',\n",
        "                       'Attribute9', 'Attribute10', 'Attribute12', 'Attribute14', 'Attribute15',\n",
        "                       'Attribute17', 'Attribute19', 'Attribute20']\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    # Apply the label encoding and update the DataFrame\n",
        "    X.loc[:, col] = label_encoders[col].fit_transform(X[col])\n",
        "\n",
        "# Clear label encoders and categorical column list\n",
        "del label_encoders, categorical_columns\n",
        "gc.collect()\n",
        "\n",
        "# Normalize the features\n",
        "scaler = MinMaxScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Apply PCA, if necessary, to reduce the number of features\n",
        "pca = PCA(n_components=18)  # Adjust components based on available memory\n",
        "X_reduced = pca.fit_transform(X_normalized)\n",
        "\n",
        "del X, X_normalized\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "# Split into training and testing sets\n",
        "# (Update train-test split with reduced features)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Clear reduced dataset\n",
        "del X_reduced\n",
        "gc.collect()\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'class_weight': [{1: 1.0, 2: 2.0}, {1: 1.0, 2: 3.0}, {1: 1.0, 2: 4.0}],\n",
        "    'alpha': [0.0001, 0.001, 0.01],  # Regularization strength\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=SGDClassifier(loss=\"log_loss\", random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    scoring='recall',\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# Convert target (y) to a 1D array (addresses warnings)\n",
        "y_train = y_train['class'].to_numpy()\n",
        "y_test = y_test['class'].to_numpy()\n",
        "\n",
        "# Update the number of qubits\n",
        "num_qubits = X_train.shape[1]  # Updated to reduced feature count\n",
        "\n",
        "# Define the Quantum Reservoir\n",
        "def create_quantum_reservoir(num_qubits, depth):\n",
        "    qubits = [cirq.GridQubit(0, i) for i in range(num_qubits)]\n",
        "    circuit = cirq.Circuit()\n",
        "    for _ in range(depth):\n",
        "        for qubit in qubits:\n",
        "            circuit.append(cirq.rx(np.random.rand() * 2 * np.pi)(qubit))\n",
        "        for i in range(len(qubits) - 1):\n",
        "            circuit.append(cirq.CNOT(qubits[i], qubits[i + 1]))\n",
        "    return circuit, qubits\n",
        "\n",
        "# Initialize quantum reservoir\n",
        "num_qubits = X_train.shape[1]  # Number of features as qubits\n",
        "reservoir_depth = 3\n",
        "quantum_circuit, quantum_qubits = create_quantum_reservoir(num_qubits, reservoir_depth)\n",
        "\n",
        "# Encode classical data into quantum states\n",
        "def encode_classical_data_optimized(data, qubits):\n",
        "    circuit = cirq.Circuit()\n",
        "    for i, value in enumerate(data[:len(qubits)]):  # Limit encoding to available qubits\n",
        "        circuit.append(cirq.rx(value * np.pi)(qubits[i]))\n",
        "    return circuit\n",
        "\n",
        "# Extract reservoir states\n",
        "def extract_reservoir_states_sparse(circuit, qubits):\n",
        "    simulator = cirq.Simulator()\n",
        "    result = simulator.simulate(circuit)\n",
        "    state_vector = csr_matrix(result.final_state_vector)  # Store as sparse matrix\n",
        "    return np.abs(state_vector.toarray()) # Take the absolute value of the state vector\n",
        "\n",
        "# Process training and testing data through the quantum reservoir\n",
        "def process_with_quantum_reservoir_in_batches(data, quantum_circuit, quantum_qubits, batch_size=100):\n",
        "    reservoir_features = []\n",
        "    for i in range(0, len(data), batch_size):\n",
        "        batch = data[i:i + batch_size]\n",
        "        for sample in batch:\n",
        "            encoded_circuit = encode_classical_data_optimized(sample.flatten(), quantum_qubits)\n",
        "            full_circuit = quantum_circuit + encoded_circuit\n",
        "            state_vector = extract_reservoir_states_sparse(full_circuit, quantum_qubits)\n",
        "            reservoir_features.append(state_vector.reshape(-1))\n",
        "    return csr_matrix(reservoir_features)\n",
        "\n",
        "reservoir_features_train = process_with_quantum_reservoir_in_batches(X_train, quantum_circuit, quantum_qubits, batch_size=50)\n",
        "del X_train  # Clear training data after processing\n",
        "gc.collect()\n",
        "\n",
        "reservoir_features_test = process_with_quantum_reservoir_in_batches(X_test, quantum_circuit, quantum_qubits, batch_size=50)\n",
        "del X_test  # Clear testing data after processing\n",
        "gc.collect()\n",
        "\n",
        "# Reshape reservoir_features_train and reservoir_features_test to 2D\n",
        "reservoir_features_train = reservoir_features_train.reshape(reservoir_features_train.shape[0], -1)\n",
        "\n",
        "# Perform grid search on training data\n",
        "grid_search.fit(reservoir_features_train, y_train)\n",
        "\n",
        "# Output best parameters and use the best model\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "reservoir_features_test = reservoir_features_test.reshape(reservoir_features_test.shape[0], -1)\n",
        "\n",
        "# Train a Logistic Regression Model\n",
        "\n",
        "# Calculate class weights before training\n",
        "classes = np.unique(y_train)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "class_weights_dict = {1: 1.0, 2: 3.0}  # Assign higher weight to minority class\n",
        "clf = SGDClassifier(loss=\"log_loss\", class_weight=class_weights_dict, random_state=42)\n",
        "\n",
        "for i in range(0, reservoir_features_train.shape[0], 100):  # Incremental training\n",
        "    batch_features = reservoir_features_train[i:i+100]\n",
        "    batch_labels = y_train[i:i+100]\n",
        "    clf.partial_fit(batch_features, batch_labels, classes=np.unique(y_train))\n",
        "\n",
        "# Evaluate the Model\n",
        "y_pred_train = clf.predict(reservoir_features_train)\n",
        "y_pred_proba_test = best_model.predict(reservoir_features_test)\n",
        "\n",
        "# Adjust threshold for bad risks (e.g., 0.4 to favor minority class) 12/16\n",
        "threshold = 0.4\n",
        "y_pred_test_adjusted = (y_pred_proba_test > threshold).astype(int)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test_adjusted) #12/16\n",
        "\n",
        "# Perform cross-validation\n",
        "scores = cross_val_score(clf, reservoir_features_train, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-Validation Accuracy Scores: {scores}\")\n",
        "print(f\"Mean Cross-Validation Accuracy: {np.mean(scores) * 100:.2f}%\")\n",
        "\n",
        "print(f\"Train Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Clear reservoir features after model evaluation\n",
        "del reservoir_features_train, reservoir_features_test\n",
        "gc.collect()\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_test_adjusted)\n",
        "\n",
        "# Example Predictions\n",
        "print(f\"Predicted Defaults (Test): {y_pred_test_adjusted[:10]}\")\n",
        "print(f\"Actual Defaults (Test): {y_test[:10]}\") # Remove .values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {'y_pred_train' : y_pred_train,\n",
        "           'y_pred_test' : y_pred_test_adjusted,\n",
        "           'train_accuracy' : train_accuracy,\n",
        "           'test_accuracy' : test_accuracy}\n",
        "\n",
        "with open('data.pkl', 'wb') as file:\n",
        "    pickle.dump(results, file)"
      ],
      "metadata": {
        "id": "4qKbRfMzGFO1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recall = recall_score(y_test, y_pred_test_adjusted, average='macro', pos_label=2)  # Focus on minority class\n",
        "print(f\"Adjusted Recall for Bad Risk: {recall:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlVhUg93tXtw",
        "outputId": "98296880-88ca-48aa-9084-7d787e3a5ece"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusted Recall for Bad Risk: 0.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1583: UserWarning: Note that pos_label (set to 2) is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXpX3Ksyv9gZ",
        "outputId": "789eac0c-ed2f-435f-dbfb-8f58ed9a20be"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[141   0]\n",
            " [ 59   0]]\n"
          ]
        }
      ]
    }
  ]
}